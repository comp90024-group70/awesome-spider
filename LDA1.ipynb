{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/byronsun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/twitter_clean.csv')\n",
    "df = df.dropna(subset=['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sd/n4qckn_55n77_95v7yphh1xw0000gn/T/ipykernel_77755/1043273477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackground_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"white\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontour_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontour_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steelblue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Generate a word cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwordcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlong_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Visualize the word cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mwordcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \"\"\"\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \"\"\"\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollocations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0mword_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munigrams_and_bigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_plurals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollocation_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;31m# remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/wordcloud/tokenization.py\u001b[0m in \u001b[0;36munigrams_and_bigrams\u001b[0;34m(words, stopwords, normalize_plurals, collocation_threshold)\u001b[0m\n\u001b[1;32m     46\u001b[0m     counts_unigrams, standard_form = process_tokens(\n\u001b[1;32m     47\u001b[0m         unigrams, normalize_plurals=normalize_plurals)\n\u001b[0;32m---> 48\u001b[0;31m     counts_bigrams, standard_form_bigrams = process_tokens(\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbigram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         normalize_plurals=normalize_plurals)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/wordcloud/tokenization.py\u001b[0m in \u001b[0;36mprocess_tokens\u001b[0;34m(words, normalize_plurals)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# merge plurals into the singular count (simple cases only)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mmerged_plurals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mkey_singular\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Join the different processed titles together.\n",
    "long_string = ','.join(list(df['cleaned_text'].values))\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sorry', 'subjected'], ['naww']]\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data = df.cleaned_text.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "print(data_words[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sorry subjected', 'naww']\n"
     ]
    }
   ],
   "source": [
    "data_lemmatized = [' '.join(sublist) for sublist in data_words]\n",
    "print(data_lemmatized[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,\n",
    "                             stop_words='english',             \n",
    "                             lowercase=True,                   \n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  \n",
    "                             max_features=100)\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(learning_method='online', n_components=20, n_jobs=-1,\n",
      "                          random_state=100)\n"
     ]
    }
   ],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=20,               # Number of topics\n",
    "                                      max_iter=10,               \n",
    "# Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          \n",
    "# Random state\n",
    "                                      batch_size=128,            \n",
    "# n docs in each learning iter\n",
    "                                      evaluate_every = -1,       \n",
    "# compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               \n",
    "# Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -13730783.103831442\n",
      "Perplexity:  115.36695113549537\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 20,\n",
      " 'n_jobs': -1,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sd/n4qckn_55n77_95v7yphh1xw0000gn/T/ipykernel_77755/3795143906.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Do the Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m GridSearchCV(cv=None, error_score='raise',\n\u001b[1;32m     10\u001b[0m        estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlearning_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"online\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m                         self._em_step(\n\u001b[0m\u001b[1;32m    631\u001b[0m                             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                             \u001b[0mtotal_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_em_step\u001b[0;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# E-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         _, suff_stats = self._e_step(\n\u001b[0m\u001b[1;32m    502\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_e_step\u001b[0;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         results = parallel(\n\u001b[0m\u001b[1;32m    445\u001b[0m             delayed(_update_doc_distribution)(\n\u001b[1;32m    446\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_update_doc_distribution\u001b[0;34m(X, exp_topic_word_distr, doc_topic_prior, max_doc_update_iter, mean_change_tol, cal_sstats, random_state)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mnorm_phi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_doc_topic_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_topic_word_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mdoc_topic_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_doc_topic_d\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_phi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_topic_word_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;31m# Note: adds doc_topic_prior to doc_topic_d, in-place.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_dirichlet_expectation_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_topic_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_doc_topic_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation(max_iter=5, learning_method='online', learning_offset=50.,random_state=0)\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)\n",
    "GridSearchCV(cv=None, error_score='raise',\n",
    "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
    "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
    "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
    "             mean_change_tol=0.001, n_components=10, n_jobs=1,\n",
    "             n_topics=None, perp_tol=0.1, random_state=None,\n",
    "             topic_word_prior=None, total_samples=1000000.0, verbose=0),\n",
    "       fit_params=None, iid=True, n_jobs=1,\n",
    "       param_grid={'n_topics': [10, 15, 20, 25, 30], 'learning_decay': [0.5, 0.7, 0.9]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda_model = lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document â€” Topic Matrix\n",
    "lda_output = best_lda_model.transform(data_vectorized)\n",
    "# column names\n",
    "topicnames = ['Topic' + str(i) for i in range(best_lda_model.n_components)]\n",
    "# index names\n",
    "docnames = ['Doc' + str(i) for i in range(len(data))]\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "# Styling\n",
    "def color_green(val):\n",
    " color = 'green' if val > .1 else 'black'\n",
    " return 'color: {col}'.format(col=color)\n",
    "def make_bold(val):\n",
    " weight = 700 if val > .1 else 400\n",
    " return 'font-weight: {weight}'.format(weight=weight)\n",
    "# Apply Style\n",
    "#df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "#df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic11</th>\n",
       "      <th>Topic12</th>\n",
       "      <th>Topic13</th>\n",
       "      <th>Topic14</th>\n",
       "      <th>Topic15</th>\n",
       "      <th>Topic16</th>\n",
       "      <th>Topic17</th>\n",
       "      <th>Topic18</th>\n",
       "      <th>Topic19</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2421463</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2421464</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2421465</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2421466</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2421467</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2421468 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7   \n",
       "Doc0          0.05    0.05    0.05    0.05    0.05    0.05    0.05    0.05  \\\n",
       "Doc1          0.05    0.05    0.05    0.05    0.05    0.05    0.05    0.05   \n",
       "Doc2          0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03   \n",
       "Doc3          0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03   \n",
       "Doc4          0.03    0.03    0.03    0.03    0.03    0.52    0.03    0.03   \n",
       "...            ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "Doc2421463    0.05    0.05    0.05    0.05    0.05    0.05    0.05    0.05   \n",
       "Doc2421464    0.03    0.03    0.03    0.03    0.03    0.52    0.03    0.03   \n",
       "Doc2421465    0.05    0.05    0.05    0.05    0.05    0.05    0.05    0.05   \n",
       "Doc2421466    0.05    0.05    0.05    0.05    0.05    0.05    0.05    0.05   \n",
       "Doc2421467    0.05    0.05    0.05    0.05    0.05    0.05    0.05    0.05   \n",
       "\n",
       "            Topic8  Topic9  ...  Topic11  Topic12  Topic13  Topic14  Topic15   \n",
       "Doc0          0.05    0.05  ...     0.05     0.05     0.05     0.05     0.05  \\\n",
       "Doc1          0.05    0.05  ...     0.05     0.05     0.05     0.05     0.05   \n",
       "Doc2          0.03    0.03  ...     0.03     0.03     0.03     0.52     0.03   \n",
       "Doc3          0.52    0.03  ...     0.03     0.03     0.03     0.03     0.03   \n",
       "Doc4          0.03    0.03  ...     0.03     0.03     0.03     0.03     0.03   \n",
       "...            ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "Doc2421463    0.05    0.05  ...     0.05     0.05     0.05     0.05     0.05   \n",
       "Doc2421464    0.03    0.03  ...     0.03     0.03     0.03     0.03     0.03   \n",
       "Doc2421465    0.05    0.05  ...     0.05     0.05     0.05     0.05     0.05   \n",
       "Doc2421466    0.05    0.05  ...     0.05     0.05     0.05     0.05     0.05   \n",
       "Doc2421467    0.05    0.05  ...     0.05     0.05     0.05     0.05     0.05   \n",
       "\n",
       "            Topic16  Topic17  Topic18  Topic19  dominant_topic  \n",
       "Doc0           0.05     0.05     0.05     0.05               0  \n",
       "Doc1           0.05     0.05     0.05     0.05               0  \n",
       "Doc2           0.03     0.03     0.03     0.03              14  \n",
       "Doc3           0.03     0.03     0.03     0.03               8  \n",
       "Doc4           0.03     0.03     0.03     0.03               5  \n",
       "...             ...      ...      ...      ...             ...  \n",
       "Doc2421463     0.05     0.05     0.05     0.05               0  \n",
       "Doc2421464     0.03     0.03     0.03     0.03               5  \n",
       "Doc2421465     0.05     0.05     0.05     0.05               0  \n",
       "Doc2421466     0.05     0.05     0.05     0.05               0  \n",
       "Doc2421467     0.05     0.05     0.05     0.05               0  \n",
       "\n",
       "[2421468 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actually</th>\n",
       "      <th>amazing</th>\n",
       "      <th>amp</th>\n",
       "      <th>australia</th>\n",
       "      <th>australian</th>\n",
       "      <th>away</th>\n",
       "      <th>bad</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>week</th>\n",
       "      <th>win</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>45456.988762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15827.002647</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>15637.401552</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32659.858317</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>24733.684706</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            actually  amazing   amp     australia  australian  away   \n",
       "Topic0      0.050000     0.05  0.05      0.050000        0.05  0.05  \\\n",
       "Topic1      0.050000     0.05  0.05      0.050000        0.05  0.05   \n",
       "Topic2      0.050000     0.05  0.05      0.050000        0.05  0.05   \n",
       "Topic3      0.050000     0.05  0.05      0.050000        0.05  0.05   \n",
       "Topic4  15637.401552     0.05  0.05  32659.858317        0.05  0.05   \n",
       "\n",
       "                 bad  beautiful  best  better  ...   way  week   win  women   \n",
       "Topic0      0.050000       0.05  0.05    0.05  ...  0.05  0.05  0.05   0.05  \\\n",
       "Topic1      0.050000       0.05  0.05    0.05  ...  0.05  0.05  0.05   0.05   \n",
       "Topic2      0.050000       0.05  0.05    0.05  ...  0.05  0.05  0.05   0.05   \n",
       "Topic3  15827.002647       0.05  0.05    0.05  ...  0.05  0.05  0.05   0.05   \n",
       "Topic4      0.050000       0.05  0.05    0.05  ...  0.05  0.05  0.05   0.05   \n",
       "\n",
       "        work  world  yeah          year  years           yes  \n",
       "Topic0  0.05   0.05  0.05      0.050000   0.05  45456.988762  \n",
       "Topic1  0.05   0.05  0.05      0.050000   0.05      0.050000  \n",
       "Topic2  0.05   0.05  0.05      0.050000   0.05      0.050000  \n",
       "Topic3  0.05   0.05  0.05      0.050000   0.05      0.050000  \n",
       "Topic4  0.05   0.05  0.05  24733.684706   0.05      0.050000  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(best_lda_model.components_)\n",
    "# Assign Column and Index\n",
    "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
    "df_topic_keywords.index = topicnames\n",
    "# View\n",
    "df_topic_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>yes</td>\n",
       "      <td>let</td>\n",
       "      <td>days</td>\n",
       "      <td>stop</td>\n",
       "      <td>care</td>\n",
       "      <td>job</td>\n",
       "      <td>start</td>\n",
       "      <td>help</td>\n",
       "      <td>change</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>need</td>\n",
       "      <td>right</td>\n",
       "      <td>maybe</td>\n",
       "      <td>help</td>\n",
       "      <td>thing</td>\n",
       "      <td>change</td>\n",
       "      <td>start</td>\n",
       "      <td>country</td>\n",
       "      <td>better</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>little</td>\n",
       "      <td>true</td>\n",
       "      <td>things</td>\n",
       "      <td>money</td>\n",
       "      <td>help</td>\n",
       "      <td>change</td>\n",
       "      <td>lot</td>\n",
       "      <td>better</td>\n",
       "      <td>thing</td>\n",
       "      <td>bit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>day</td>\n",
       "      <td>government</td>\n",
       "      <td>looks</td>\n",
       "      <td>bad</td>\n",
       "      <td>morning</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>today</td>\n",
       "      <td>good</td>\n",
       "      <td>like</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>new</td>\n",
       "      <td>australia</td>\n",
       "      <td>year</td>\n",
       "      <td>sure</td>\n",
       "      <td>night</td>\n",
       "      <td>home</td>\n",
       "      <td>man</td>\n",
       "      <td>old</td>\n",
       "      <td>end</td>\n",
       "      <td>actually</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>like</td>\n",
       "      <td>people</td>\n",
       "      <td>bong</td>\n",
       "      <td>say</td>\n",
       "      <td>lot</td>\n",
       "      <td>country</td>\n",
       "      <td>thing</td>\n",
       "      <td>actually</td>\n",
       "      <td>looks</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>hope</td>\n",
       "      <td>week</td>\n",
       "      <td>away</td>\n",
       "      <td>women</td>\n",
       "      <td>better</td>\n",
       "      <td>home</td>\n",
       "      <td>family</td>\n",
       "      <td>start</td>\n",
       "      <td>country</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>thank</td>\n",
       "      <td>best</td>\n",
       "      <td>big</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>thing</td>\n",
       "      <td>today</td>\n",
       "      <td>way</td>\n",
       "      <td>country</td>\n",
       "      <td>family</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>love</td>\n",
       "      <td>life</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>family</td>\n",
       "      <td>way</td>\n",
       "      <td>man</td>\n",
       "      <td>thing</td>\n",
       "      <td>better</td>\n",
       "      <td>country</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>great</td>\n",
       "      <td>work</td>\n",
       "      <td>really</td>\n",
       "      <td>happy</td>\n",
       "      <td>covid</td>\n",
       "      <td>today</td>\n",
       "      <td>start</td>\n",
       "      <td>morning</td>\n",
       "      <td>home</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 10</th>\n",
       "      <td>amp</td>\n",
       "      <td>good</td>\n",
       "      <td>time</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>morning</td>\n",
       "      <td>help</td>\n",
       "      <td>family</td>\n",
       "      <td>country</td>\n",
       "      <td>start</td>\n",
       "      <td>change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 11</th>\n",
       "      <td>got</td>\n",
       "      <td>want</td>\n",
       "      <td>lol</td>\n",
       "      <td>team</td>\n",
       "      <td>tonight</td>\n",
       "      <td>watch</td>\n",
       "      <td>today</td>\n",
       "      <td>home</td>\n",
       "      <td>start</td>\n",
       "      <td>thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 12</th>\n",
       "      <td>photo</td>\n",
       "      <td>today</td>\n",
       "      <td>posted</td>\n",
       "      <td>way</td>\n",
       "      <td>morning</td>\n",
       "      <td>better</td>\n",
       "      <td>thing</td>\n",
       "      <td>help</td>\n",
       "      <td>thought</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 13</th>\n",
       "      <td>going</td>\n",
       "      <td>said</td>\n",
       "      <td>labor</td>\n",
       "      <td>feel</td>\n",
       "      <td>vote</td>\n",
       "      <td>win</td>\n",
       "      <td>change</td>\n",
       "      <td>election</td>\n",
       "      <td>better</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 14</th>\n",
       "      <td>make</td>\n",
       "      <td>come</td>\n",
       "      <td>yeah</td>\n",
       "      <td>long</td>\n",
       "      <td>looking</td>\n",
       "      <td>bit</td>\n",
       "      <td>hard</td>\n",
       "      <td>sure</td>\n",
       "      <td>way</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 15</th>\n",
       "      <td>think</td>\n",
       "      <td>years</td>\n",
       "      <td>live</td>\n",
       "      <td>old</td>\n",
       "      <td>country</td>\n",
       "      <td>change</td>\n",
       "      <td>actually</td>\n",
       "      <td>thing</td>\n",
       "      <td>time</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 16</th>\n",
       "      <td>know</td>\n",
       "      <td>que</td>\n",
       "      <td>australian</td>\n",
       "      <td>nice</td>\n",
       "      <td>election</td>\n",
       "      <td>help</td>\n",
       "      <td>country</td>\n",
       "      <td>thing</td>\n",
       "      <td>people</td>\n",
       "      <td>change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 17</th>\n",
       "      <td>game</td>\n",
       "      <td>getting</td>\n",
       "      <td>real</td>\n",
       "      <td>watch</td>\n",
       "      <td>start</td>\n",
       "      <td>better</td>\n",
       "      <td>thing</td>\n",
       "      <td>way</td>\n",
       "      <td>home</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 18</th>\n",
       "      <td>look</td>\n",
       "      <td>world</td>\n",
       "      <td>amazing</td>\n",
       "      <td>country</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>end</td>\n",
       "      <td>change</td>\n",
       "      <td>man</td>\n",
       "      <td>like</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 19</th>\n",
       "      <td>thanks</td>\n",
       "      <td>mate</td>\n",
       "      <td>support</td>\n",
       "      <td>help</td>\n",
       "      <td>today</td>\n",
       "      <td>family</td>\n",
       "      <td>old</td>\n",
       "      <td>country</td>\n",
       "      <td>lot</td>\n",
       "      <td>amp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word 0      Word 1      Word 2     Word 3     Word 4     Word 5   \n",
       "Topic 0      yes         let        days       stop       care        job  \\\n",
       "Topic 1     need       right       maybe       help      thing     change   \n",
       "Topic 2   little        true      things      money       help     change   \n",
       "Topic 3      day  government       looks        bad    morning  beautiful   \n",
       "Topic 4      new   australia        year       sure      night       home   \n",
       "Topic 5     like      people        bong        say        lot    country   \n",
       "Topic 6     hope        week        away      women     better       home   \n",
       "Topic 7    thank        best         big  beautiful      thing      today   \n",
       "Topic 8     love        life   beautiful     family        way        man   \n",
       "Topic 9    great        work      really      happy      covid      today   \n",
       "Topic 10     amp        good        time  beautiful    morning       help   \n",
       "Topic 11     got        want         lol       team    tonight      watch   \n",
       "Topic 12   photo       today      posted        way    morning     better   \n",
       "Topic 13   going        said       labor       feel       vote        win   \n",
       "Topic 14    make        come        yeah       long    looking        bit   \n",
       "Topic 15   think       years        live        old    country     change   \n",
       "Topic 16    know         que  australian       nice   election       help   \n",
       "Topic 17    game     getting        real      watch      start     better   \n",
       "Topic 18    look       world     amazing    country  beautiful        end   \n",
       "Topic 19  thanks        mate     support       help      today     family   \n",
       "\n",
       "            Word 6    Word 7   Word 8    Word 9  \n",
       "Topic 0      start      help   change   country  \n",
       "Topic 1      start   country   better    people  \n",
       "Topic 2        lot    better    thing       bit  \n",
       "Topic 3      today      good     like     start  \n",
       "Topic 4        man       old      end  actually  \n",
       "Topic 5      thing  actually    looks      help  \n",
       "Topic 6     family     start  country     today  \n",
       "Topic 7        way   country   family      help  \n",
       "Topic 8      thing    better  country       end  \n",
       "Topic 9      start   morning     home       way  \n",
       "Topic 10    family   country    start    change  \n",
       "Topic 11     today      home    start   thought  \n",
       "Topic 12     thing      help  thought   country  \n",
       "Topic 13    change  election   better       way  \n",
       "Topic 14      hard      sure      way    better  \n",
       "Topic 15  actually     thing     time    better  \n",
       "Topic 16   country     thing   people    change  \n",
       "Topic 17     thing       way     home       end  \n",
       "Topic 18    change       man     like    better  \n",
       "Topic 19       old   country      lot       amp  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=10)\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>yes</td>\n",
       "      <td>let</td>\n",
       "      <td>days</td>\n",
       "      <td>stop</td>\n",
       "      <td>care</td>\n",
       "      <td>job</td>\n",
       "      <td>start</td>\n",
       "      <td>help</td>\n",
       "      <td>change</td>\n",
       "      <td>country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>need</td>\n",
       "      <td>right</td>\n",
       "      <td>maybe</td>\n",
       "      <td>help</td>\n",
       "      <td>thing</td>\n",
       "      <td>change</td>\n",
       "      <td>start</td>\n",
       "      <td>country</td>\n",
       "      <td>better</td>\n",
       "      <td>people</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>little</td>\n",
       "      <td>true</td>\n",
       "      <td>things</td>\n",
       "      <td>money</td>\n",
       "      <td>help</td>\n",
       "      <td>change</td>\n",
       "      <td>lot</td>\n",
       "      <td>better</td>\n",
       "      <td>thing</td>\n",
       "      <td>bit</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>day</td>\n",
       "      <td>government</td>\n",
       "      <td>looks</td>\n",
       "      <td>bad</td>\n",
       "      <td>morning</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>today</td>\n",
       "      <td>good</td>\n",
       "      <td>like</td>\n",
       "      <td>start</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>new</td>\n",
       "      <td>australia</td>\n",
       "      <td>year</td>\n",
       "      <td>sure</td>\n",
       "      <td>night</td>\n",
       "      <td>home</td>\n",
       "      <td>man</td>\n",
       "      <td>old</td>\n",
       "      <td>end</td>\n",
       "      <td>actually</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>like</td>\n",
       "      <td>people</td>\n",
       "      <td>bong</td>\n",
       "      <td>say</td>\n",
       "      <td>lot</td>\n",
       "      <td>country</td>\n",
       "      <td>thing</td>\n",
       "      <td>actually</td>\n",
       "      <td>looks</td>\n",
       "      <td>help</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>hope</td>\n",
       "      <td>week</td>\n",
       "      <td>away</td>\n",
       "      <td>women</td>\n",
       "      <td>better</td>\n",
       "      <td>home</td>\n",
       "      <td>family</td>\n",
       "      <td>start</td>\n",
       "      <td>country</td>\n",
       "      <td>today</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>thank</td>\n",
       "      <td>best</td>\n",
       "      <td>big</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>thing</td>\n",
       "      <td>today</td>\n",
       "      <td>way</td>\n",
       "      <td>country</td>\n",
       "      <td>family</td>\n",
       "      <td>help</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>love</td>\n",
       "      <td>life</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>family</td>\n",
       "      <td>way</td>\n",
       "      <td>man</td>\n",
       "      <td>thing</td>\n",
       "      <td>better</td>\n",
       "      <td>country</td>\n",
       "      <td>end</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>great</td>\n",
       "      <td>work</td>\n",
       "      <td>really</td>\n",
       "      <td>happy</td>\n",
       "      <td>covid</td>\n",
       "      <td>today</td>\n",
       "      <td>start</td>\n",
       "      <td>morning</td>\n",
       "      <td>home</td>\n",
       "      <td>way</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 10</th>\n",
       "      <td>amp</td>\n",
       "      <td>good</td>\n",
       "      <td>time</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>morning</td>\n",
       "      <td>help</td>\n",
       "      <td>family</td>\n",
       "      <td>country</td>\n",
       "      <td>start</td>\n",
       "      <td>change</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 11</th>\n",
       "      <td>got</td>\n",
       "      <td>want</td>\n",
       "      <td>lol</td>\n",
       "      <td>team</td>\n",
       "      <td>tonight</td>\n",
       "      <td>watch</td>\n",
       "      <td>today</td>\n",
       "      <td>home</td>\n",
       "      <td>start</td>\n",
       "      <td>thought</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 12</th>\n",
       "      <td>photo</td>\n",
       "      <td>today</td>\n",
       "      <td>posted</td>\n",
       "      <td>way</td>\n",
       "      <td>morning</td>\n",
       "      <td>better</td>\n",
       "      <td>thing</td>\n",
       "      <td>help</td>\n",
       "      <td>thought</td>\n",
       "      <td>country</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 13</th>\n",
       "      <td>going</td>\n",
       "      <td>said</td>\n",
       "      <td>labor</td>\n",
       "      <td>feel</td>\n",
       "      <td>vote</td>\n",
       "      <td>win</td>\n",
       "      <td>change</td>\n",
       "      <td>election</td>\n",
       "      <td>better</td>\n",
       "      <td>way</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 14</th>\n",
       "      <td>make</td>\n",
       "      <td>come</td>\n",
       "      <td>yeah</td>\n",
       "      <td>long</td>\n",
       "      <td>looking</td>\n",
       "      <td>bit</td>\n",
       "      <td>hard</td>\n",
       "      <td>sure</td>\n",
       "      <td>way</td>\n",
       "      <td>better</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 15</th>\n",
       "      <td>think</td>\n",
       "      <td>years</td>\n",
       "      <td>live</td>\n",
       "      <td>old</td>\n",
       "      <td>country</td>\n",
       "      <td>change</td>\n",
       "      <td>actually</td>\n",
       "      <td>thing</td>\n",
       "      <td>time</td>\n",
       "      <td>better</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 16</th>\n",
       "      <td>know</td>\n",
       "      <td>que</td>\n",
       "      <td>australian</td>\n",
       "      <td>nice</td>\n",
       "      <td>election</td>\n",
       "      <td>help</td>\n",
       "      <td>country</td>\n",
       "      <td>thing</td>\n",
       "      <td>people</td>\n",
       "      <td>change</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 17</th>\n",
       "      <td>game</td>\n",
       "      <td>getting</td>\n",
       "      <td>real</td>\n",
       "      <td>watch</td>\n",
       "      <td>start</td>\n",
       "      <td>better</td>\n",
       "      <td>thing</td>\n",
       "      <td>way</td>\n",
       "      <td>home</td>\n",
       "      <td>end</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 18</th>\n",
       "      <td>look</td>\n",
       "      <td>world</td>\n",
       "      <td>amazing</td>\n",
       "      <td>country</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>end</td>\n",
       "      <td>change</td>\n",
       "      <td>man</td>\n",
       "      <td>like</td>\n",
       "      <td>better</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 19</th>\n",
       "      <td>thanks</td>\n",
       "      <td>mate</td>\n",
       "      <td>support</td>\n",
       "      <td>help</td>\n",
       "      <td>today</td>\n",
       "      <td>family</td>\n",
       "      <td>old</td>\n",
       "      <td>country</td>\n",
       "      <td>lot</td>\n",
       "      <td>amp</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word 0      Word 1      Word 2     Word 3     Word 4     Word 5   \n",
       "Topic 0      yes         let        days       stop       care        job  \\\n",
       "Topic 1     need       right       maybe       help      thing     change   \n",
       "Topic 2   little        true      things      money       help     change   \n",
       "Topic 3      day  government       looks        bad    morning  beautiful   \n",
       "Topic 4      new   australia        year       sure      night       home   \n",
       "Topic 5     like      people        bong        say        lot    country   \n",
       "Topic 6     hope        week        away      women     better       home   \n",
       "Topic 7    thank        best         big  beautiful      thing      today   \n",
       "Topic 8     love        life   beautiful     family        way        man   \n",
       "Topic 9    great        work      really      happy      covid      today   \n",
       "Topic 10     amp        good        time  beautiful    morning       help   \n",
       "Topic 11     got        want         lol       team    tonight      watch   \n",
       "Topic 12   photo       today      posted        way    morning     better   \n",
       "Topic 13   going        said       labor       feel       vote        win   \n",
       "Topic 14    make        come        yeah       long    looking        bit   \n",
       "Topic 15   think       years        live        old    country     change   \n",
       "Topic 16    know         que  australian       nice   election       help   \n",
       "Topic 17    game     getting        real      watch      start     better   \n",
       "Topic 18    look       world     amazing    country  beautiful        end   \n",
       "Topic 19  thanks        mate     support       help      today     family   \n",
       "\n",
       "            Word 6    Word 7   Word 8    Word 9 Topics  \n",
       "Topic 0      start      help   change   country      1  \n",
       "Topic 1      start   country   better    people      2  \n",
       "Topic 2        lot    better    thing       bit      3  \n",
       "Topic 3      today      good     like     start      4  \n",
       "Topic 4        man       old      end  actually      5  \n",
       "Topic 5      thing  actually    looks      help     6   \n",
       "Topic 6     family     start  country     today      7  \n",
       "Topic 7        way   country   family      help      8  \n",
       "Topic 8      thing    better  country       end      9  \n",
       "Topic 9      start   morning     home       way     10  \n",
       "Topic 10    family   country    start    change      a  \n",
       "Topic 11     today      home    start   thought      b  \n",
       "Topic 12     thing      help  thought   country      c  \n",
       "Topic 13    change  election   better       way      d  \n",
       "Topic 14      hard      sure      way    better      e  \n",
       "Topic 15  actually     thing     time    better      f  \n",
       "Topic 16   country     thing   people    change      g  \n",
       "Topic 17     thing       way     home       end      h  \n",
       "Topic 18    change       man     like    better      i  \n",
       "Topic 19       old   country      lot       amp      j  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Topics = [\"1\",\"2\",\"3\",\"4\",\"5\", \"6 \", \"7\", \"8\", \"9\", \"10\", 'a','b','c','d','e','f','g','h','i','j']\n",
    "df_topic_keywords[\"Topics\"]=Topics\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lemmatization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sd/n4qckn_55n77_95v7yphh1xw0000gn/T/ipykernel_77755/658944108.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Predict the topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmytext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Very Useful in diabetes age 30. I need control sugar. thanks Good deal\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0minfer_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmytext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/sd/n4qckn_55n77_95v7yphh1xw0000gn/T/ipykernel_77755/658944108.py\u001b[0m in \u001b[0;36mpredict_topic\u001b[0;34m(text, nlp)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmytext_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_to_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Step 2: Lemmatize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmytext_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmytext_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_postags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NOUN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADJ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VERB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Step 3: Vectorize transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmytext_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmytext_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lemmatization' is not defined"
     ]
    }
   ],
   "source": [
    "# Define function to predict topic for a given text document.\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp = spacy.load(\"en_core_web_sm\",disable=['parser', 'ner'])\n",
    "def predict_topic(text, nlp=nlp):\n",
    "    global sent_to_words\n",
    "    global lemmatization\n",
    "# Step 1: Clean with simple_preprocess\n",
    "    mytext_2 = list(sent_to_words(text))\n",
    "# Step 2: Lemmatize\n",
    "    mytext_3 = lemmatization(mytext_2, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "# Step 3: Vectorize transform\n",
    "    mytext_4 = vectorizer.transform(mytext_3)\n",
    "# Step 4: LDA Transform\n",
    "    topic_probability_scores = best_lda_model.transform(mytext_4)\n",
    "    topic = df_topic_keywords.iloc[np.argmax(topic_probability_scores), 1:14].values.tolist()\n",
    "    \n",
    "    # Step 5: Infer Topic\n",
    "    infer_topic = df_topic_keywords.iloc[np.argmax(topic_probability_scores), -1]\n",
    "    \n",
    "    #topic_guess = df_topic_keywords.iloc[np.argmax(topic_probability_scores), Topics]\n",
    "    return infer_topic, topic, topic_probability_scores\n",
    "# Predict the topic\n",
    "mytext = [\"Very Useful in diabetes age 30. I need control sugar. thanks Good deal\"]\n",
    "infer_topic, topic, prob_scores = predict_topic(text = mytext)\n",
    "print(topic)\n",
    "print(infer_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_predict_topic(text):\n",
    " text = [text]\n",
    " infer_topic, topic, prob_scores = predict_topic(text = text)\n",
    " return(infer_topic)\n",
    "df[\"Topic_key_word\"]= df['Translated_Review'].apply(apply_predict_topic)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Topic_key_word').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('googlePlayStore_review_LDA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the k-means clusters\n",
    "from sklearn.cluster import KMeans\n",
    "clusters = KMeans(n_clusters=15, random_state=100).fit_predict(lda_output)\n",
    "# Build the Singular Value Decomposition(SVD) model\n",
    "svd_model = TruncatedSVD(n_components=2)  # 2 components\n",
    "lda_output_svd = svd_model.fit_transform(lda_output)\n",
    "# X and Y axes of the plot using SVD decomposition\n",
    "x = lda_output_svd[:, 0]\n",
    "y = lda_output_svd[:, 1]\n",
    "# Weights for the 15 columns of lda_output, for each component\n",
    "print(\"Component's weights: \\n\", np.round(svd_model.components_, 2))\n",
    "# Percentage of total information in 'lda_output' explained by the two components\n",
    "print(\"Perc of Variance Explained: \\n\", np.round(svd_model.explained_variance_ratio_, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(x, y, c=clusters)\n",
    "plt.xlabel('Component 2')\n",
    "plt.xlabel('Component 1')\n",
    "plt.title(\"Segregation of Topic Clusters\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "def similar_documents(text, doc_topic_probs, documents = data, nlp=nlp, top_n=5, verbose=False):\n",
    "    topic, x  = predict_topic(text)\n",
    "    dists = euclidean_distances(x.reshape(1, -1), doc_topic_probs)[0]\n",
    "    doc_ids = np.argsort(dists)[:top_n]\n",
    "    if verbose:        \n",
    "        print(\"Topic KeyWords: \", topic)\n",
    "        print(\"Topic Prob Scores of text: \", np.round(x, 1))\n",
    "        print(\"Most Similar Doc's Probs:  \", np.round(doc_topic_probs[doc_ids], 1))\n",
    "    return doc_ids, np.take(documents, doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = ['I think they are really helpful']\n",
    "doc_ids, docs = similar_documents(text=mytext, doc_topic_probs=lda_output, documents = data, top_n=1, verbose=True)\n",
    "print('\\n', docs[0][:500])\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
